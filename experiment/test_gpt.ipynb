{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL.Image\n",
    "client = OpenAI(\n",
    "    base_url='https://api.openai-proxy.org/v1',\n",
    "    api_key='Your Keys',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image):\n",
    "    # Check if the image is a string path and open it\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)   \n",
    "        \n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    img_bytes = buffered.getvalue()\n",
    "    img_base64 = base64.b64encode(img_bytes)\n",
    "    img_str = img_base64.decode('utf-8')\n",
    "    \n",
    "    return img_str\n",
    "\n",
    "def encode_image_gpt4v(image):\n",
    "    return 'data:image/jpeg;base64,' + encode_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(img_path):\n",
    "    question='{\"Task\": \"Please provide me with the quantity, position, and relationship of all different objects in the given image in JSON format.\\\n",
    "    For quantity, count all the quantities of different objects. If it is 0, do not output that class,\\\n",
    "    For the positions of different objects, the position of each individual unit in each type of object needs to be output(the positions are divided into nine grids, namely the top left corner),\\\n",
    "    top,top right corner,left,center,right,left lower corner,lower,right lower corner)ã€‚\\\n",
    "    For relationships, output the relationships between all objects in the image in the form of triplets, [object2, relation,object2],\\\n",
    "    Please refer to the following JSON format for specific formatting, and use this JSON format for output (just output one JSON)\",\\\n",
    "    \"Restriction\": \"Provide JSON response in a format stricter than<format> without wrapping it in code block markers\"\\\n",
    "    \"format\":{\"number\":{\"man\":3,\"car\":2,\"desk\":1,\"woman\":3},\"location\":{\"man\":{1:\"center\",2:\"top\"},\"car\":{1,:\"top right corner\",2:left} },\"relationship\":[[\"man\",\"near to\",\"car\"],[\"car\",\"on\",\"load\"],[\"woman\",\"has\",\"car\"]]} }'\n",
    "\n",
    "\n",
    "    \n",
    "    img_url=encode_image_gpt4v(img_path)\n",
    "    \n",
    "    messages=[{\n",
    "        'role':'user',\n",
    "        'content':[\n",
    "            {\n",
    "                \"text\":question,\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\":{\"url\":img_url}\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    )\n",
    "\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507.jpg\n",
      "508.jpg\n",
      "509.jpg\n",
      "510.jpg\n",
      "512.jpg\n",
      "513.jpg\n",
      "514.jpg\n",
      "515.jpg\n",
      "517.jpg\n",
      "518.jpg\n",
      "521.jpg\n",
      "524.jpg\n",
      "525.jpg\n",
      "526.jpg\n",
      "529.jpg\n",
      "530.jpg\n",
      "531.jpg\n",
      "532.jpg\n",
      "533.jpg\n",
      "535.jpg\n",
      "536.jpg\n",
      "537.jpg\n",
      "538.jpg\n",
      "540.jpg\n",
      "543.jpg\n",
      "544.jpg\n",
      "545.jpg\n",
      "549.jpg\n",
      "551.jpg\n",
      "554.jpg\n",
      "556.jpg\n",
      "558.jpg\n",
      "559.jpg\n",
      "560.jpg\n",
      "561.jpg\n",
      "563.jpg\n",
      "564.jpg\n",
      "565.jpg\n",
      "566.jpg\n",
      "567.jpg\n",
      "568.jpg\n",
      "569.jpg\n",
      "570.jpg\n",
      "572.jpg\n",
      "573.jpg\n",
      "574.jpg\n",
      "576.jpg\n",
      "579.jpg\n",
      "580.jpg\n",
      "582.jpg\n",
      "583.jpg\n",
      "584.jpg\n",
      "585.jpg\n",
      "586.jpg\n",
      "587.jpg\n",
      "588.jpg\n",
      "590.jpg\n",
      "591.jpg\n",
      "592.jpg\n",
      "593.jpg\n",
      "594.jpg\n",
      "596.jpg\n",
      "598.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "dir_list=os.listdir('JPEGImages')\n",
    "\n",
    "for i in dir_list[-63:]:\n",
    "    result=get_result(os.path.join('JPEGImages',i)).choices[0].message.content\n",
    "\n",
    "    with open(os.path.join('gpt_answer',i[:-4]+'.pickle'),'wb') as f:\n",
    "        pickle.dump(result,f)\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
