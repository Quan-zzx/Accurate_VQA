{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import nltk\n",
    "import demjson3\n",
    "from nltk.corpus import wordnet\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_synonyms_split(word_list,word2):\n",
    "    \"\"\"第一个是一个列表\"\"\"\n",
    "    right=[]\n",
    "\n",
    "    for i in word_list:\n",
    "        for j in word2:\n",
    "            right.append(are_synonyms(i,j))\n",
    "\n",
    "    if True in right:\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def has_hypernym_or_hyponym_split(word_list,word2):\n",
    "    \"\"\"第一个是一个列表\"\"\"\n",
    "    right=[]\n",
    "\n",
    "    for i in word_list:\n",
    "        for j in word2:\n",
    "            right.append(has_hypernym_or_hyponym(i,j))\n",
    "\n",
    "    if True in right:\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def are_synonyms(word1, word2):\n",
    "    # 获取word1的所有同义词集\n",
    "    synsets1 = wordnet.synsets(word1)\n",
    "    \n",
    "    # 获取word2的所有同义词集\n",
    "    synsets2 = wordnet.synsets(word2)\n",
    "  \n",
    "    # 检查是否有交集\n",
    "    for synset1 in synsets1:\n",
    "        for synset2 in synsets2:\n",
    "            if synset1 == synset2:\n",
    "                return True\n",
    "    \n",
    "    # 计算路径相似度作为备选方案\n",
    "    for synset1 in synsets1:\n",
    "        for synset2 in synsets2:\n",
    "            if synset1.path_similarity(synset2) is not None and synset1.path_similarity(synset2) > 0.8:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def has_hypernym_or_hyponym(word1, word2):\n",
    "    # 获取word1的所有同义词集\n",
    "    synsets1 = wordnet.synsets(word1)\n",
    "    \n",
    "    # 获取word2的所有同义词集\n",
    "    synsets2 = wordnet.synsets(word2)\n",
    "    \n",
    "    # 检查是否存在上位词或下位词关系\n",
    "    for synset1 in synsets1:\n",
    "        for synset2 in synsets2:\n",
    "            # 检查synset1是否是synset2的上位词\n",
    "            if synset1 in synset2.hypernyms():\n",
    "                return True\n",
    "            \n",
    "            # 检查synset2是否是synset1的上位词\n",
    "            if synset2 in synset1.hypernyms():\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def count_common_elements_with_repetition(list1, list2):\n",
    "    # 创建字典来存储每个元素在两个列表中的出现次数\n",
    "    count_dict1 = {}\n",
    "    count_dict2 = {}\n",
    "    \n",
    "    # 统计第一个列表中每个元素的出现次数\n",
    "    for element in list1:\n",
    "        if element in count_dict1:\n",
    "            count_dict1[element] += 1\n",
    "        else:\n",
    "            count_dict1[element] = 1\n",
    "    \n",
    "    # 统计第二个列表中每个元素的出现次数\n",
    "    for element in list2:\n",
    "        if element in count_dict2:\n",
    "            count_dict2[element] += 1\n",
    "        else:\n",
    "            count_dict2[element] = 1\n",
    "    \n",
    "    # 计算共同元素的数量\n",
    "    common_count = 0\n",
    "    for element in count_dict1:\n",
    "        if element in count_dict2:\n",
    "            # 取两个列表中该元素出现次数的较小值\n",
    "            common_count += min(count_dict1[element], count_dict2[element])\n",
    "    \n",
    "    return common_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_right_single(ground_truth,predict):\n",
    "    \"\"\"\n",
    "        计算单张图片的预测准确率\n",
    "        分成四个 计数，位置，关系，total\n",
    "    \"\"\"\n",
    "\n",
    "    category_right=0\n",
    "    number_right=0\n",
    "    loc_right=0\n",
    "\n",
    "    ready_list=[]\n",
    "\n",
    "    for i in predict['number'].keys():\n",
    "        for j in ground_truth['number'].keys():\n",
    "\n",
    "            if j in ready_list:\n",
    "                continue\n",
    "\n",
    "            i_split=re.split(r'[_-]',i)\n",
    "            j_split=re.split(r'[_-]',j)\n",
    "\n",
    "\n",
    "            if are_synonyms_split(i_split,j_split):        ##标签对应上了\n",
    "                ready_list.append(j)        #加入已经完成配对\n",
    "\n",
    "                category_right+=1\n",
    "                if predict['number'][i]==ground_truth['number'][j]:     #统计数量一样，加1\n",
    "                    number_right+=1\n",
    "\n",
    "\n",
    "                ###计算位置对了几个\n",
    "                loc_right+=count_common_elements_with_repetition(list(predict['location'][i].values()),ground_truth['location'][j])\n",
    "                break\n",
    "\n",
    "\n",
    "    rel_right=0        ###计算关系预测对了几个   逻辑上 关系三元组，一个个去比\n",
    "\n",
    "    for i in predict['relationship']:\n",
    "        for j in ground_truth['relationship']:\n",
    "\n",
    "            i_split=re.split(r'[\\s_-]',i[0])\n",
    "            j_split=re.split(r'[\\s_-]',j[0])        \n",
    "\n",
    "            if are_synonyms_split(i_split,j_split):        \n",
    "\n",
    "                i_split=re.split(r'[\\s_-]',i[1])\n",
    "                j_split=re.split(r'[\\s_-]',j[1]) \n",
    "\n",
    "                if len(i_split)<=2:\n",
    "                    i_split=i_split[0]\n",
    "                else:\n",
    "                    i_split=i_split[1]\n",
    "\n",
    "                if len(j_split)<=2:\n",
    "                    j_split=j_split[0]\n",
    "                else:\n",
    "                    j_split=j_split[1]\n",
    "\n",
    "                if are_synonyms(i_split,j_split):        \n",
    "\n",
    "                    i_split=re.split(r'[\\s_-]',i[2])\n",
    "                    j_split=re.split(r'[\\s_-]',j[2])\n",
    "\n",
    "                    \n",
    "                    if are_synonyms_split(i_split,j_split):        \n",
    "                        rel_right+=1\n",
    "                        break\n",
    "\n",
    "    ### 计算总数\n",
    "    \n",
    "    number_num=len(ground_truth['number'].keys())\n",
    "    loc_num=sum(ground_truth['number'].values())\n",
    "    rel_num=len(ground_truth['relationship'])\n",
    "\n",
    "    gen_num=len(predict['number'].keys())\n",
    "    gen_loc=sum(predict['number'].values())\n",
    "    gen_rel=len(predict['relationship'])\n",
    "\n",
    "    ###计算 precision\n",
    "    if gen_num==0:\n",
    "        number_precision=0\n",
    "        category_precision=0\n",
    "    else:\n",
    "        category_precision=category_right/gen_num\n",
    "        number_precision=number_right/gen_num\n",
    "    if gen_loc==0:\n",
    "        loc_precision=0\n",
    "    else:\n",
    "        loc_precision=loc_right/gen_loc\n",
    "    if gen_rel==0:\n",
    "        rel_precision=0\n",
    "    else:\n",
    "        rel_precision=rel_right/gen_rel\n",
    "\n",
    "    ### 计算recall\n",
    "    if number_num==0:\n",
    "        number_recall=1\n",
    "        category_recall=1\n",
    "    else:\n",
    "        category_recall=category_right/number_num\n",
    "        number_recall=number_right/number_num\n",
    "\n",
    "    if loc_num==0:\n",
    "        loc_recall=1\n",
    "    else:\n",
    "        loc_recall=loc_right/loc_num\n",
    "    \n",
    "    if rel_num==0:\n",
    "        rel_recall=1\n",
    "    else:\n",
    "        rel_recall=rel_right/rel_num\n",
    "\n",
    "    #### 计算F1\n",
    "    if category_precision==0 and category_recall==0:\n",
    "        category_f1=0\n",
    "    else:\n",
    "        category_f1=2*(category_precision*category_recall)/(category_precision+category_recall)\n",
    "    if number_precision==0 and number_recall==0:\n",
    "        num_f1=0\n",
    "    else:\n",
    "        num_f1=2*(number_precision*number_recall)/(number_precision+number_recall)\n",
    "    \n",
    "    if loc_precision==0 and loc_recall==0:\n",
    "        loc_f1=0\n",
    "    else:\n",
    "        loc_f1=2*(loc_precision*loc_recall)/(loc_precision+loc_recall)\n",
    "    \n",
    "    if rel_precision==0 and rel_recall==0:\n",
    "        rel_f1=0\n",
    "    else:\n",
    "        rel_f1=2*(rel_precision*rel_recall)/(rel_precision+rel_recall)\n",
    "\n",
    "    return category_precision,number_precision,loc_precision,rel_precision,category_recall,number_recall,loc_recall,rel_recall,category_f1,num_f1,loc_f1,rel_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446.pickle\n",
      "447.pickle\n",
      "451.pickle\n",
      "452.pickle\n",
      "454.pickle\n",
      "455.pickle\n",
      "457.pickle\n",
      "458.pickle\n",
      "460.pickle\n",
      "461.pickle\n",
      "462.pickle\n",
      "463.pickle\n",
      "464.pickle\n",
      "465.pickle\n",
      "467.pickle\n",
      "470.pickle\n",
      "472.pickle\n",
      "473.pickle\n",
      "474.pickle\n",
      "475.pickle\n",
      "476.pickle\n",
      "478.pickle\n",
      "479.pickle\n",
      "480.pickle\n",
      "484.pickle\n",
      "485.pickle\n",
      "488.pickle\n",
      "489.pickle\n",
      "491.pickle\n",
      "493.pickle\n",
      "494.pickle\n",
      "497.pickle\n",
      "498.pickle\n",
      "499.pickle\n",
      "500.pickle\n",
      "501.pickle\n",
      "502.pickle\n",
      "507.pickle\n",
      "508.pickle\n",
      "509.pickle\n",
      "510.pickle\n",
      "512.pickle\n",
      "513.pickle\n",
      "514.pickle\n",
      "515.pickle\n",
      "517.pickle\n",
      "518.pickle\n",
      "521.pickle\n",
      "524.pickle\n",
      "525.pickle\n",
      "526.pickle\n",
      "529.pickle\n",
      "530.pickle\n",
      "531.pickle\n",
      "532.pickle\n",
      "533.pickle\n",
      "535.pickle\n",
      "536.pickle\n",
      "537.pickle\n",
      "538.pickle\n",
      "540.pickle\n",
      "543.pickle\n",
      "544.pickle\n",
      "545.pickle\n",
      "549.pickle\n",
      "551.pickle\n",
      "554.pickle\n",
      "556.pickle\n",
      "558.pickle\n",
      "559.pickle\n",
      "560.pickle\n",
      "563.pickle\n",
      "564.pickle\n",
      "565.pickle\n",
      "566.pickle\n",
      "567.pickle\n",
      "568.pickle\n",
      "569.pickle\n",
      "570.pickle\n",
      "572.pickle\n",
      "573.pickle\n",
      "574.pickle\n",
      "576.pickle\n",
      "579.pickle\n",
      "580.pickle\n",
      "582.pickle\n",
      "583.pickle\n",
      "584.pickle\n",
      "585.pickle\n",
      "586.pickle\n",
      "587.pickle\n",
      "588.pickle\n",
      "590.pickle\n",
      "591.pickle\n",
      "592.pickle\n",
      "593.pickle\n",
      "594.pickle\n",
      "596.pickle\n",
      "598.pickle\n"
     ]
    }
   ],
   "source": [
    "acc_list=[]\n",
    "\n",
    "answer_list=os.listdir('gemini_answer')\n",
    "\n",
    "for i,answer in enumerate(answer_list):\n",
    "\n",
    "    with open(os.path.join('gemini_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "    predict=demjson3.decode(data)\n",
    "    ground_truth=ground_truth_total[i+299]\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_numpy=np.array(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6477, 0.3526, 0.2217, 0.0357, 0.1615, 0.0908, 0.0555, 0.0095,\n",
       "       0.2488, 0.1389, 0.08  , 0.0142])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4,suppress=True)\n",
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_numpy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_numpy>0.5)[:,4:8].mean(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list=[]\n",
    "\n",
    "answer_list=os.listdir('gpt_answer')\n",
    "\n",
    "for i,answer in enumerate(answer_list):\n",
    "\n",
    "    with open(os.path.join('gpt_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "    predict=demjson3.decode(data)\n",
    "    ground_truth=ground_truth_total[i+299]\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4924, 0.2685, 0.1725, 0.0051, 0.0908, 0.0584, 0.0324, 0.0001,\n",
       "       0.1472, 0.0921, 0.0504, 0.0002])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_numpy=np.array(acc_list)\n",
    "\n",
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_numpy>0.5)[:,4:8].mean(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vg_data/VG_ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2339172.pickle\n",
      "2339171.pickle\n",
      "2339170.pickle\n",
      "2339168.pickle\n",
      "2339167.pickle\n",
      "2339166.pickle\n",
      "2339165.pickle\n",
      "2339164.pickle\n",
      "2339163.pickle\n",
      "2339162.pickle\n",
      "2339161.pickle\n",
      "2339160.pickle\n",
      "2339159.pickle\n",
      "2339158.pickle\n",
      "2339157.pickle\n",
      "2339156.pickle\n",
      "2339155.pickle\n",
      "2339154.pickle\n",
      "2339153.pickle\n",
      "2339152.pickle\n",
      "2339151.pickle\n",
      "2339150.pickle\n",
      "2339149.pickle\n",
      "2339148.pickle\n",
      "2339147.pickle\n",
      "2339146.pickle\n",
      "2339145.pickle\n",
      "2339144.pickle\n",
      "2339143.pickle\n",
      "2339142.pickle\n",
      "2339141.pickle\n",
      "2339140.pickle\n",
      "2339139.pickle\n",
      "2339138.pickle\n",
      "2339137.pickle\n",
      "2339136.pickle\n",
      "2339135.pickle\n",
      "2339134.pickle\n",
      "2339133.pickle\n",
      "2339132.pickle\n",
      "2339131.pickle\n",
      "2339130.pickle\n",
      "2339129.pickle\n",
      "2339127.pickle\n",
      "2339126.pickle\n",
      "2339125.pickle\n",
      "2339124.pickle\n",
      "2339123.pickle\n",
      "2339122.pickle\n",
      "2339075.pickle\n",
      "2339074.pickle\n",
      "2339073.pickle\n",
      "2339072.pickle\n",
      "2339071.pickle\n",
      "2339070.pickle\n",
      "2339069.pickle\n",
      "2339068.pickle\n",
      "2339067.pickle\n",
      "2339066.pickle\n",
      "2339065.pickle\n",
      "2339064.pickle\n",
      "2339063.pickle\n",
      "2339062.pickle\n",
      "2339061.pickle\n",
      "2339060.pickle\n",
      "2339059.pickle\n",
      "2339058.pickle\n",
      "2339057.pickle\n",
      "2339056.pickle\n",
      "2339055.pickle\n",
      "2339054.pickle\n",
      "2339053.pickle\n",
      "2339052.pickle\n",
      "2339051.pickle\n",
      "2339050.pickle\n",
      "2339049.pickle\n",
      "2339048.pickle\n",
      "2339047.pickle\n",
      "2339046.pickle\n",
      "2339045.pickle\n",
      "2339044.pickle\n",
      "2339043.pickle\n",
      "2339042.pickle\n",
      "2339041.pickle\n",
      "2339040.pickle\n",
      "2339039.pickle\n",
      "2339037.pickle\n",
      "2339036.pickle\n",
      "2339034.pickle\n",
      "2339033.pickle\n",
      "2339031.pickle\n",
      "2339030.pickle\n",
      "2339029.pickle\n",
      "2339028.pickle\n",
      "2339027.pickle\n",
      "2339026.pickle\n",
      "2339025.pickle\n",
      "2339024.pickle\n",
      "2339023.pickle\n",
      "2339022.pickle\n",
      "2339021.pickle\n",
      "2339020.pickle\n",
      "2339019.pickle\n",
      "2339018.pickle\n",
      "2339017.pickle\n",
      "2339016.pickle\n",
      "2339015.pickle\n",
      "2339014.pickle\n",
      "2339013.pickle\n",
      "2339012.pickle\n",
      "2339011.pickle\n",
      "2339010.pickle\n",
      "2339009.pickle\n",
      "2339008.pickle\n",
      "2339007.pickle\n",
      "2339006.pickle\n",
      "2339005.pickle\n",
      "2339004.pickle\n",
      "2339003.pickle\n",
      "2339002.pickle\n",
      "2338999.pickle\n",
      "2338998.pickle\n",
      "2338996.pickle\n",
      "2338995.pickle\n",
      "2338994.pickle\n",
      "2338993.pickle\n",
      "2338992.pickle\n",
      "2338991.pickle\n",
      "2338989.pickle\n",
      "2338988.pickle\n",
      "2338987.pickle\n",
      "2338986.pickle\n",
      "2338985.pickle\n",
      "2338984.pickle\n"
     ]
    }
   ],
   "source": [
    "acc_list=[]\n",
    "k=0\n",
    "\n",
    "answer_list=os.listdir('VG_gemini_answer')\n",
    "\n",
    "for i,answer in enumerate(answer_list[::-1]):\n",
    "\n",
    "    with open(os.path.join('VG_gemini_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "\n",
    "    try:\n",
    "        predict=demjson3.decode(data)\n",
    "    except demjson3.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "    ground_truth=ground_truth_total[int(answer[:-7])]\n",
    "\n",
    "    if len(ground_truth['relationship'])==0:\n",
    "        continue\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n",
    "\n",
    "    k+=1\n",
    "    if k==100:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': {'donut': '153'},\n",
       " 'location': {'donut': {'1': 'top left corner',\n",
       "   '2': 'center',\n",
       "   '3': 'top right corner',\n",
       "   '4': 'left',\n",
       "   '5': 'center',\n",
       "   '6': 'right',\n",
       "   '7': 'left lower corner',\n",
       "   '8': 'lower',\n",
       "   '9': 'right lower corner'}},\n",
       " 'relationship': []}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5708, 0.3358, 0.1169, 0.0488, 0.2304, 0.1355, 0.063 , 0.0327,\n",
       "       0.3   , 0.1748, 0.0662, 0.0296])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_numpy=np.array(acc_list)\n",
    "np.set_printoptions(precision=4)\n",
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_numpy>0.55)[:,4:8].mean(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vg_data/VG_ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2339172.pickle\n",
      "2339171.pickle\n",
      "2339170.pickle\n",
      "2339169.pickle\n",
      "2339168.pickle\n",
      "2339167.pickle\n",
      "2339166.pickle\n",
      "2339165.pickle\n",
      "2339164.pickle\n",
      "2339163.pickle\n",
      "2339162.pickle\n",
      "2339161.pickle\n",
      "2339160.pickle\n",
      "2339159.pickle\n",
      "2339158.pickle\n",
      "2339157.pickle\n",
      "2339156.pickle\n",
      "2339155.pickle\n",
      "2339154.pickle\n",
      "2339153.pickle\n",
      "2339152.pickle\n",
      "2339151.pickle\n",
      "2339150.pickle\n",
      "2339149.pickle\n",
      "2339148.pickle\n",
      "2339147.pickle\n",
      "2339146.pickle\n",
      "2339145.pickle\n",
      "2339144.pickle\n",
      "2339143.pickle\n",
      "2339142.pickle\n",
      "2339141.pickle\n",
      "2339140.pickle\n",
      "2339139.pickle\n",
      "2339138.pickle\n",
      "2339137.pickle\n",
      "2339136.pickle\n",
      "2339135.pickle\n",
      "2339134.pickle\n",
      "2339133.pickle\n",
      "2339132.pickle\n",
      "2339131.pickle\n",
      "2339130.pickle\n",
      "2339129.pickle\n",
      "2339127.pickle\n",
      "2339126.pickle\n",
      "2339125.pickle\n",
      "2339124.pickle\n",
      "2339123.pickle\n",
      "2339122.pickle\n",
      "2339075.pickle\n",
      "2339074.pickle\n",
      "2339073.pickle\n",
      "2339072.pickle\n",
      "2339071.pickle\n",
      "2339070.pickle\n",
      "2339069.pickle\n",
      "2339068.pickle\n",
      "2339067.pickle\n",
      "2339066.pickle\n",
      "2339065.pickle\n",
      "2339064.pickle\n",
      "2339063.pickle\n",
      "2339062.pickle\n",
      "2339061.pickle\n",
      "2339060.pickle\n",
      "2339059.pickle\n",
      "2339058.pickle\n",
      "2339057.pickle\n",
      "2339056.pickle\n",
      "2339055.pickle\n",
      "2339054.pickle\n",
      "2339053.pickle\n",
      "2339052.pickle\n",
      "2339051.pickle\n",
      "2339050.pickle\n",
      "2339049.pickle\n",
      "2339048.pickle\n",
      "2339047.pickle\n",
      "2339046.pickle\n",
      "2339045.pickle\n",
      "2339044.pickle\n",
      "2339043.pickle\n",
      "2339042.pickle\n",
      "2339041.pickle\n",
      "2339040.pickle\n",
      "2339039.pickle\n",
      "2339037.pickle\n",
      "2339036.pickle\n",
      "2339034.pickle\n",
      "2339033.pickle\n",
      "2339031.pickle\n",
      "2339030.pickle\n",
      "2339029.pickle\n",
      "2339028.pickle\n",
      "2339027.pickle\n",
      "2339026.pickle\n",
      "2339025.pickle\n",
      "2339024.pickle\n",
      "2339023.pickle\n",
      "2339022.pickle\n",
      "2339021.pickle\n",
      "2339020.pickle\n",
      "2339019.pickle\n",
      "2339018.pickle\n",
      "2339017.pickle\n",
      "2339016.pickle\n",
      "2339015.pickle\n",
      "2339014.pickle\n",
      "2339013.pickle\n",
      "2339012.pickle\n",
      "2339011.pickle\n",
      "2339010.pickle\n",
      "2339009.pickle\n",
      "2339008.pickle\n",
      "2339007.pickle\n",
      "2339006.pickle\n",
      "2339005.pickle\n",
      "2339004.pickle\n",
      "2339003.pickle\n",
      "2339002.pickle\n",
      "2339001.pickle\n",
      "2339000.pickle\n",
      "2338999.pickle\n",
      "2338998.pickle\n",
      "2338997.pickle\n",
      "2338996.pickle\n",
      "2338995.pickle\n",
      "2338994.pickle\n",
      "2338993.pickle\n",
      "2338992.pickle\n",
      "2338991.pickle\n",
      "2338990.pickle\n"
     ]
    }
   ],
   "source": [
    "acc_list=[]\n",
    "\n",
    "answer_list=os.listdir('VG_gpt_answer')\n",
    "\n",
    "k=0\n",
    "\n",
    "for i,answer in enumerate(answer_list[::-1]):\n",
    "\n",
    "    with open(os.path.join('VG_gpt_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "    \n",
    "    try:\n",
    "        predict=demjson3.decode(data)\n",
    "    except demjson3.JSONDecodeError:\n",
    "        continue\n",
    "    ground_truth=ground_truth_total[int(answer[:-7])]\n",
    "\n",
    "    if len(ground_truth['relationship'])==0:\n",
    "        continue\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n",
    "    k+=1\n",
    "    if k==100:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6083, 0.3233, 0.144 , 0.0408, 0.2586, 0.1475, 0.0719, 0.0295,\n",
       "       0.3427, 0.1918, 0.0886, 0.0255])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_numpy=np.array(acc_list)\n",
    "\n",
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_numpy>0.55)[:,4:8].mean(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446.pickle\n",
      "447.pickle\n",
      "451.pickle\n",
      "452.pickle\n",
      "454.pickle\n",
      "455.pickle\n",
      "457.pickle\n",
      "458.pickle\n",
      "460.pickle\n",
      "461.pickle\n",
      "462.pickle\n",
      "463.pickle\n",
      "464.pickle\n",
      "465.pickle\n",
      "467.pickle\n",
      "470.pickle\n",
      "472.pickle\n",
      "473.pickle\n",
      "474.pickle\n",
      "475.pickle\n",
      "476.pickle\n",
      "478.pickle\n",
      "479.pickle\n",
      "480.pickle\n",
      "484.pickle\n",
      "485.pickle\n",
      "488.pickle\n",
      "489.pickle\n",
      "491.pickle\n",
      "493.pickle\n",
      "494.pickle\n",
      "497.pickle\n",
      "498.pickle\n",
      "499.pickle\n",
      "500.pickle\n",
      "501.pickle\n",
      "502.pickle\n",
      "507.pickle\n",
      "508.pickle\n",
      "509.pickle\n",
      "510.pickle\n",
      "512.pickle\n",
      "513.pickle\n",
      "514.pickle\n",
      "515.pickle\n",
      "517.pickle\n",
      "518.pickle\n",
      "521.pickle\n",
      "524.pickle\n",
      "525.pickle\n",
      "526.pickle\n",
      "529.pickle\n",
      "530.pickle\n",
      "531.pickle\n",
      "532.pickle\n",
      "533.pickle\n",
      "535.pickle\n",
      "536.pickle\n",
      "537.pickle\n",
      "538.pickle\n",
      "540.pickle\n",
      "543.pickle\n",
      "544.pickle\n",
      "545.pickle\n",
      "549.pickle\n",
      "551.pickle\n",
      "554.pickle\n",
      "556.pickle\n",
      "558.pickle\n",
      "559.pickle\n",
      "560.pickle\n",
      "563.pickle\n",
      "564.pickle\n",
      "565.pickle\n",
      "566.pickle\n",
      "567.pickle\n",
      "568.pickle\n",
      "569.pickle\n",
      "570.pickle\n",
      "572.pickle\n",
      "573.pickle\n",
      "574.pickle\n",
      "576.pickle\n",
      "579.pickle\n",
      "580.pickle\n",
      "582.pickle\n",
      "583.pickle\n",
      "584.pickle\n",
      "585.pickle\n",
      "586.pickle\n",
      "587.pickle\n",
      "588.pickle\n",
      "590.pickle\n",
      "591.pickle\n",
      "592.pickle\n",
      "593.pickle\n",
      "594.pickle\n",
      "596.pickle\n",
      "598.pickle\n"
     ]
    }
   ],
   "source": [
    "acc_list=[]\n",
    "\n",
    "answer_list=os.listdir('Qwen_answer')\n",
    "\n",
    "for i,answer in enumerate(answer_list):\n",
    "\n",
    "    with open(os.path.join('Qwen_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "    predict=demjson3.decode(data)\n",
    "    ground_truth=ground_truth_total[i+299]\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_numpy=np.array(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4163, 0.2084, 0.1151, 0.016 , 0.0877, 0.0508, 0.0229, 0.0055,\n",
       "       0.1387, 0.0778, 0.0345, 0.0075])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4,suppress=True)\n",
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005050505050505051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(acc_numpy>0.5)[:,4:8].mean(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('VG_data/VG_ground_truth.pickle','rb') as f:\n",
    "    ground_truth_total=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2339172.pickle\n",
      "2339171.pickle\n",
      "2339170.pickle\n",
      "2339169.pickle\n",
      "2339168.pickle\n",
      "2339167.pickle\n",
      "2339166.pickle\n",
      "2339165.pickle\n",
      "2339164.pickle\n",
      "2339163.pickle\n",
      "2339162.pickle\n",
      "2339161.pickle\n",
      "2339160.pickle\n",
      "2339159.pickle\n",
      "2339158.pickle\n",
      "2339157.pickle\n",
      "2339156.pickle\n",
      "2339155.pickle\n",
      "2339154.pickle\n",
      "2339153.pickle\n",
      "2339152.pickle\n",
      "2339151.pickle\n",
      "2339150.pickle\n",
      "2339149.pickle\n",
      "2339148.pickle\n",
      "2339147.pickle\n",
      "2339146.pickle\n",
      "2339145.pickle\n",
      "2339144.pickle\n",
      "2339143.pickle\n",
      "2339142.pickle\n",
      "2339141.pickle\n",
      "2339140.pickle\n",
      "2339139.pickle\n",
      "2339138.pickle\n",
      "2339137.pickle\n",
      "2339136.pickle\n",
      "2339135.pickle\n",
      "2339134.pickle\n",
      "2339133.pickle\n",
      "2339132.pickle\n",
      "2339131.pickle\n",
      "2339130.pickle\n",
      "2339129.pickle\n",
      "2339127.pickle\n",
      "2339126.pickle\n",
      "2339125.pickle\n",
      "2339124.pickle\n",
      "2339123.pickle\n",
      "2339122.pickle\n",
      "2339121.pickle\n",
      "2339120.pickle\n",
      "2339119.pickle\n",
      "2339118.pickle\n",
      "2339117.pickle\n",
      "2339116.pickle\n",
      "2339115.pickle\n",
      "2339114.pickle\n",
      "2339113.pickle\n",
      "2339112.pickle\n",
      "2339110.pickle\n",
      "2339109.pickle\n",
      "2339108.pickle\n",
      "2339107.pickle\n",
      "2339106.pickle\n",
      "2339105.pickle\n",
      "2339104.pickle\n",
      "2339103.pickle\n",
      "2339102.pickle\n",
      "2339101.pickle\n",
      "2339100.pickle\n",
      "2339099.pickle\n",
      "2339098.pickle\n",
      "2339097.pickle\n",
      "2339096.pickle\n",
      "2339095.pickle\n",
      "2339094.pickle\n",
      "2339093.pickle\n",
      "2339092.pickle\n",
      "2339091.pickle\n",
      "2339090.pickle\n",
      "2339089.pickle\n",
      "2339088.pickle\n",
      "2339087.pickle\n",
      "2339086.pickle\n",
      "2339085.pickle\n",
      "2339084.pickle\n",
      "2339083.pickle\n",
      "2339082.pickle\n",
      "2339081.pickle\n",
      "2339080.pickle\n",
      "2339079.pickle\n",
      "2339078.pickle\n",
      "2339077.pickle\n",
      "2339076.pickle\n",
      "2339075.pickle\n",
      "2339074.pickle\n",
      "2339073.pickle\n",
      "2339072.pickle\n",
      "2339071.pickle\n",
      "2339070.pickle\n",
      "2339069.pickle\n",
      "2339068.pickle\n",
      "2339067.pickle\n",
      "2339066.pickle\n",
      "2339065.pickle\n",
      "2339064.pickle\n",
      "2339063.pickle\n",
      "2339062.pickle\n",
      "2339061.pickle\n",
      "2339060.pickle\n",
      "2339059.pickle\n",
      "2339058.pickle\n",
      "2339057.pickle\n",
      "2339056.pickle\n",
      "2339055.pickle\n",
      "2339054.pickle\n",
      "2339053.pickle\n",
      "2339052.pickle\n",
      "2339051.pickle\n",
      "2339050.pickle\n",
      "2339049.pickle\n",
      "2339048.pickle\n",
      "2339047.pickle\n",
      "2339046.pickle\n",
      "2339045.pickle\n",
      "2339044.pickle\n",
      "2339043.pickle\n",
      "2339042.pickle\n",
      "2339041.pickle\n",
      "2339040.pickle\n",
      "2339039.pickle\n",
      "2339037.pickle\n",
      "2339036.pickle\n",
      "2339034.pickle\n",
      "2339033.pickle\n",
      "2339031.pickle\n",
      "2339030.pickle\n",
      "2339029.pickle\n",
      "2339028.pickle\n",
      "2339027.pickle\n",
      "2339026.pickle\n",
      "2339025.pickle\n",
      "2339024.pickle\n",
      "2339023.pickle\n",
      "2339022.pickle\n",
      "2339021.pickle\n",
      "2339020.pickle\n",
      "2339019.pickle\n",
      "2339018.pickle\n",
      "2339017.pickle\n",
      "2339016.pickle\n",
      "2339015.pickle\n",
      "2339014.pickle\n",
      "2339013.pickle\n",
      "2339012.pickle\n",
      "2339011.pickle\n",
      "2339010.pickle\n",
      "2339009.pickle\n",
      "2339008.pickle\n",
      "2339007.pickle\n",
      "2339006.pickle\n",
      "2339005.pickle\n",
      "2339004.pickle\n"
     ]
    }
   ],
   "source": [
    "acc_list=[]\n",
    "\n",
    "k=0\n",
    "\n",
    "answer_list=os.listdir('VG_Qwen_answer')\n",
    "\n",
    "for i,answer in enumerate(answer_list[::-1]):\n",
    "\n",
    "    with open(os.path.join('VG_Qwen_answer',answer),'rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        print(answer)\n",
    "\n",
    "    try:                                    ##跳过错误\n",
    "        predict=demjson3.decode(data)\n",
    "    except demjson3.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "    ground_truth=ground_truth_total[int(answer[:-7])]\n",
    "\n",
    "    if len(ground_truth['relationship'])==0:\n",
    "        continue\n",
    "\n",
    "    acc_list.append(list(compute_right_single(ground_truth,predict)))\n",
    "\n",
    "    k+=1\n",
    "    if k==100:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "acc_numpy=np.array(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5417, 0.3593, 0.1285, 0.0537, 0.3017, 0.2032, 0.0764, 0.0505,\n",
       "       0.3412, 0.2257, 0.0853, 0.0377])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_numpy.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(acc_numpy>0.55)[:,4:8].mean(1).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scene_graph_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
